{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from scipy.stats import mode\n",
    "import gc  # Import the garbage collection module\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix, f1_score\n",
    "import pickle\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Activation, Dropout, Dense, Flatten, MaxPooling1D\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras import regularizers\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import keras\n",
    "\n",
    "def sort_cmp (key):\n",
    "    ans = 0\n",
    "    for c in key:\n",
    "        if (c.isdigit() == True):\n",
    "            ans = ans * 10 + int (c)\n",
    "    return ans\n",
    "\n",
    "def load_test_data(dir_rec, save=False):\n",
    "    x, y = [], [] \n",
    "    print (dir_rec)\n",
    "    for file in sorted(glob.glob(dir_rec + \"/*.wav\")):\n",
    "        # load an audio file as a floating point time series.    \n",
    "        data, sr = librosa.load(file)\n",
    "        #print ('shape:', data.shape, ' ', sr)\n",
    "        # extract features from audio files into numpy array\n",
    "        #feature = extract_feature(data, sr, mfcc=True/*, chroma=True, mel=True)\n",
    "        seg = np.array (divide_into_segments (data, sr))\n",
    "        i = 0\n",
    "        for s in seg:\n",
    "            feature = extract_feature(s, sr, mfcc=True, chroma=True, mel=True)\n",
    "            x.append(feature)\n",
    "            #x_orig.append (s)\n",
    "            i+= 1\n",
    "            if (i == 5):\n",
    "                break\n",
    "        file_name = os.path.basename(file)\n",
    "        #print (file_name)\n",
    "        if (file_name.count ('Neutral') > 0):\n",
    "            emotion = file_name.split ('.')[0].split ('_')[4]\n",
    "        else:\n",
    "            emotion = file_name.split ('.')[0].split ('_')[4]\n",
    "        \n",
    "        if (emotion == 'Calmness'):\n",
    "            emotion = 'Calmness'    \n",
    "        # get emotion label from the file name\n",
    "        i = 0\n",
    "        for s in seg:\n",
    "            y.append(emotions.index (emotion))\n",
    "            i += 1\n",
    "            if (i == 5):\n",
    "                break\n",
    "    \n",
    "    if save==True:\n",
    "        np.save('X', np.array(x))\n",
    "        np.save('y', y)\n",
    "        \n",
    "    return np.array(x), y\n",
    "def divide_into_segments (data, sr, seg_dur_seconds = 5):\n",
    "    segment_length = sr * seg_dur_seconds\n",
    "    num_sections = int(np.floor(len(data) / segment_length))\n",
    "    split = []\n",
    "    for i in range(num_sections):\n",
    "        t = data[i * segment_length: (i + 1) * segment_length]\n",
    "        split.append(t)\n",
    "    return split \n",
    "\n",
    "def extract_feature(data, sr, mfcc, chroma, mel):\n",
    "    if chroma:                          \n",
    "        stft = np.abs(librosa.stft(data))  \n",
    "    result = np.array([])\n",
    "    if mfcc:                          \n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "    if chroma:                          \n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T,axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "        \n",
    "    if mel:           \n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sr).T,axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "        \n",
    "    return result \n",
    "\n",
    "def proc_data (file, emotion):\n",
    "    x = []\n",
    "    y = []\n",
    "    data, sr = librosa.load(file)\n",
    "    seg = np.array (divide_into_segments (data, sr))\n",
    "    i = 0\n",
    "    for s in seg:\n",
    "        feature = extract_feature(s, sr, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        i+= 1\n",
    "        if (i == 5):\n",
    "            break\n",
    "    i = 0\n",
    "    for s in seg:\n",
    "        y.append(emotions.index (emotion))\n",
    "        i += 1\n",
    "        if (i == 5):\n",
    "            break\n",
    "    return x, y\n",
    "\n",
    "def extract_index_video(filename):\n",
    "    key = (int (filename.split ('/')[-1].split('_')[1]), int (filename.split ('/')[-1].split('_')[5]))\n",
    "    return key\n",
    "\n",
    "def extract_index_audio(filename):\n",
    "    if (filename.count ('neutral') > 0):\n",
    "        return (int (filename.split ('/')[-1].split('_')[1]), 0)\n",
    "    \n",
    "    key = (int (filename.split ('/')[-1].split('_')[1]), int (filename.split ('/')[-1].split('_')[3]))\n",
    "    \n",
    "    return key\n",
    "\n",
    "acc = []\n",
    "fscore = []\n",
    "confusion = []\n",
    "\n",
    "root_folder = \"../Dropbox/EAV\"\n",
    "\n",
    "emotions = [\"Anger\", \"Neutral\", \"Sadness\", \"Calmness\", \"Happiness\"]\n",
    "for subfolder in sorted(os.listdir(root_folder), key = sort_cmp):\n",
    "    print(subfolder)\n",
    "    categorized_files = {emotion: [] for emotion in emotions}\n",
    "    subfolder_path = os.path.join(root_folder, subfolder)\n",
    "    audio_path = os.path.join(subfolder_path, 'Audio')\n",
    "    data, labels = [], []\n",
    "    if os.path.exists(audio_path):\n",
    "        all_files = sorted(os.listdir(audio_path))\n",
    "        for file in all_files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                for emotion in emotions:\n",
    "                    if emotion in file:\n",
    "                        if (emotion != 'Neutral' and file.count ('Neutral') > 0):\n",
    "                            continue\n",
    "                        audio_path2 = os.path.join(audio_path, file)\n",
    "                        categorized_files[emotion].append(audio_path2)\n",
    "        \n",
    "        X, y = load_test_data(audio_path)\n",
    "        idx = 0\n",
    "        \n",
    "        for class_index, emotion in enumerate(emotions):\n",
    "            for file_index, audio_path2 in enumerate(categorized_files[emotion]):\n",
    "                x,y = proc_data (audio_path2, emotion)        \n",
    "                data.extend(x)\n",
    "                labels.extend(y)\n",
    "                idx+=1\n",
    "\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        x_test = []\n",
    "        y_test = []\n",
    "        \n",
    "        for i, emotion in enumerate (emotions):\n",
    "            x_train.extend (data [i*80: i*80 + 40])\n",
    "            y_train.extend (labels [i*80: i*80 + 40])\n",
    "            x_test.extend (data [i*80 + 40: i*80 + 80])\n",
    "            y_test.extend (labels [i*80 + 40: i*80 + 80])\n",
    "        \n",
    "        x_train = np.array(x_train)\n",
    "        x_test = np.array(x_test)\n",
    "        y_train = np.array(y_train)\n",
    "        y_test = np.array(y_test)\n",
    "        x_train = np.expand_dims(x_train, axis=2)\n",
    "        x_test = np.expand_dims(x_test, axis=2)\n",
    "         \n",
    "        identity_matrix = np.eye(len(emotions))\n",
    "        train_labels_one_hot = np.array([identity_matrix[label] for label in y_train])\n",
    "        test_labels_one_hot = np.array([identity_matrix[label] for label in y_test])\n",
    "        \n",
    "        audio_model = Sequential()\n",
    "        audio_model.add(Conv1D(256, 5,padding='same', input_shape=(180,1))) # 1st layer\n",
    "        audio_model.add(Activation('relu'))\n",
    "        audio_model.add(Conv1D(128, 5,padding='same', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))) # 2nd layer\n",
    "        audio_model.add(Activation('relu'))\n",
    "        audio_model.add(Dropout(0.1))\n",
    "        audio_model.add(MaxPooling1D(pool_size=(8)))\n",
    "        audio_model.add(Conv1D(128, 5,padding='same', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))) # 3rd layer\n",
    "        audio_model.add(Activation('relu'))\n",
    "        audio_model.add(Conv1D(128, 5,padding='same', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))) # 4th layer\n",
    "        audio_model.add(Activation('relu'))\n",
    "        audio_model.add(Dropout(0.5))\n",
    "        audio_model.add(Flatten())\n",
    "        audio_model.add(Dense(units=5,\n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4),\n",
    "                        activity_regularizer=regularizers.l2(1e-5)\n",
    "                        )\n",
    "        ) # 7th layer\n",
    "        audio_model.add(Activation('softmax'))\n",
    "        audio_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        audio_model.fit(x_train, train_labels_one_hot, validation_data=(x_test, test_labels_one_hot), epochs=100, batch_size=64, verbose = False)\n",
    "        loss, accuracy = audio_model.evaluate(x_test, test_labels_one_hot)\n",
    "        y_pred = audio_model.predict (x_test)\n",
    "        f1 = f1_score(y_test,np.argmax(y_pred, axis=-1),average='weighted')\n",
    "        acc.append (accuracy)\n",
    "        fscore.append (f1)\n",
    "        confusion_emotions = [\"Anger\", \"Neutral\", \"Sadness\", \"Calmness\", \"Happiness\"]\n",
    "        cm = metrics.confusion_matrix(y_test, np.argmax(y_pred, axis=-1))\n",
    "        confusion.append (cm)\n",
    "        print(f\"Audio Accuracy for {subfolder} : {accuracy * 100:.2f}%\")\n",
    "        print ('F1: ', f1)\n",
    "        print ('Confusion:', cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
