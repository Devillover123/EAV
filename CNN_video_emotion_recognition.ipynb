{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92db771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from scipy.stats import mode\n",
    "import gc  # Import the garbage collection module\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import sklearn.metrics as metrics\n",
    "IMG_HEIGHT, IMG_WIDTH = 480, 640\n",
    "from scipy.stats import mode\n",
    "\n",
    "NEW_HEIGHT, NEW_WIDTH = IMG_HEIGHT // 2, IMG_WIDTH // 2\n",
    "start_row, start_col = (IMG_HEIGHT - NEW_HEIGHT) // 2, (IMG_WIDTH - NEW_WIDTH) // 2\n",
    "end_row, end_col = start_row + NEW_HEIGHT, start_col + NEW_WIDTH\n",
    "\n",
    "class ChannelAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.shared_layer_one = Dense(input_shape[-1] // self.ratio,\n",
    "                                      activation='relu', \n",
    "                                      kernel_initializer='he_normal',\n",
    "                                      use_bias=True, \n",
    "                                      bias_initializer='zeros')\n",
    "        self.shared_layer_two = Dense(input_shape[-1],\n",
    "                                      kernel_initializer='he_normal',\n",
    "                                      use_bias=True, \n",
    "                                      bias_initializer='zeros')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_pool = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "        max_pool = tf.keras.layers.GlobalMaxPooling2D()(inputs)\n",
    "\n",
    "        avg_pool = self.shared_layer_one(avg_pool)\n",
    "        max_pool = self.shared_layer_one(max_pool)\n",
    "\n",
    "        avg_pool = self.shared_layer_two(avg_pool)\n",
    "        max_pool = self.shared_layer_two(max_pool)\n",
    "\n",
    "        return avg_pool + max_pool\n",
    "\n",
    "def sort_cmp (key):\n",
    "    ans = 0\n",
    "    for c in key:\n",
    "        if (c.isdigit() == True):\n",
    "            ans = ans * 10 + int (c)\n",
    "    return ans\n",
    "\n",
    "acc = []\n",
    "fscore = []\n",
    "confusion = []\n",
    "\n",
    "root_folder = \"../Dropbox/EAV\"\n",
    "emotions = [\"Anger\", \"Neutral\", \"Sadness\", \"Calmness\", \"Happiness\"]\n",
    "IMG_HEIGHT, IMG_WIDTH = 480, 640\n",
    "for subfolder in sorted(os.listdir(root_folder), key = sort_cmp):\n",
    "    subfolder_path = os.path.join(root_folder, subfolder)\n",
    "    audio_video_folder_path = os.path.join(subfolder_path, \"\")\n",
    "    video_path = os.path.join(subfolder_path, 'Video')\n",
    "    data_array = np.zeros(shape=(20000, 224, 224, 3, 1))\n",
    "    data, labels = [], []\n",
    "    datav, labelsv = [], []\n",
    "    if os.path.exists(video_path):\n",
    "        \n",
    "        all_files = sorted(os.listdir(video_path))\n",
    "        categorized_files_v = {emotion: [] for emotion in emotions}\n",
    "        for file in all_files:\n",
    "            if \"Speaking\" in file and file.endswith(\".mp4\"):\n",
    "                for emotion in emotions:\n",
    "                    if emotion in file:\n",
    "                        video_path_cur = os.path.join(video_path, file)\n",
    "                        categorized_files_v[emotion].append(video_path_cur)\n",
    "        \n",
    "        print(categorized_files_v[\"Anger\"])\n",
    "        idx = 0\n",
    "        for class_index, emotion in enumerate([\"Anger\", \"Neutral\", \"Sadness\", \"Calmness\", \"Happiness\"]):\n",
    "            for file_index, video_path in enumerate(categorized_files_v[emotion]):\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                if cap.isOpened():\n",
    "                    frame_index = 1                    \n",
    "                    while True:                        \n",
    "                        ret, frame = cap.read()\n",
    "                        if not ret:\n",
    "                            break\n",
    "                        if frame_index % 3 == 0 and frame_index < 601:\n",
    "                            resizedImg = cv2.resize(frame, (224, 224)).reshape(224, 224, 3, 1) / 255.0\n",
    "                            data_array[idx] = resizedImg                            \n",
    "                            idx += 1   \n",
    "                            labelsv.append(class_index)\n",
    "                        frame_index += 1\n",
    "                    cap.release()\n",
    "                else:\n",
    "                    print(f\"Error opening video file: {video_path}\")\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        x_test = []\n",
    "        y_test = []\n",
    "        \n",
    "        x_trainv = []\n",
    "        y_trainv = []\n",
    "        x_testv = []\n",
    "        y_testv = []\n",
    "        \n",
    "        for i, emotion in enumerate (emotions):\n",
    "            class_start = i * 4000\n",
    "            class_middle = class_start + 2000\n",
    "            class_end = class_middle + 2000\n",
    "\n",
    "            x_trainv.extend(data_array[class_start:class_middle])\n",
    "            x_testv.extend(data_array[class_middle:class_end])\n",
    "\n",
    "            y_trainv.extend(labelsv[class_start:class_middle])\n",
    "            y_testv.extend(labelsv[class_middle:class_end])\n",
    "            \n",
    "        identity_matrix = np.eye(len(emotions))\n",
    "        train_labels_one_hot = np.array([identity_matrix[label] for label in y_trainv])\n",
    "        test_labels_one_hot = np.array([identity_matrix[label] for label in y_testv])\n",
    "        \n",
    "        x_trainv = np.array(x_trainv)\n",
    "        x_testv = np.array(x_testv)\n",
    "        y_trainv = np.array(y_trainv)\n",
    "        y_testv = np.array(y_testv)\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "        # Add custom layers for 5-class classification\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        attention = ChannelAttention()(base_model.output)\n",
    "        x = Multiply()([x, attention])\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        predictions = Dense(5, activation='softmax')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "        # Freeze the layers of the base model (so they don't get trained)\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(x_trainv, train_labels_one_hot, epochs=100, batch_size=64)\n",
    "\n",
    "        # Evaluate the model (with test data and labels)\n",
    "        # Replace resized_data and labels with your test data and labels\n",
    "        test_loss, test_acc = model.evaluate(x_testv, test_labels_one_hot, verbose=2)\n",
    "        \n",
    "        print('\\nTest accuracy:', test_acc)\n",
    "        loss, accuracy = model.evaluate(x_testv, test_labels_one_hot)\n",
    "        print(f\"Video Accuracy: {accuracy * 100:.2f}%\")\n",
    "        y_pred = model.predict (x_testv)\n",
    "        confusion_emotions = [\"Anger\", \"Neutral\", \"Sadness\", \"Calmness\", \"Happiness\"]\n",
    "        predicted_classes = np.argmax(model.predict(x_testv), axis=1)\n",
    "        true_classes = np.argmax(test_labels_one_hot, axis=1)\n",
    "        trials_predicted = predicted_classes.reshape(-1, 50)\n",
    "        predicted_most_frequent_classes = mode(trials_predicted, axis=1)[0].flatten()\n",
    "        print(predicted_most_frequent_classes)\n",
    "        trials_true = true_classes.reshape(-1, 50)\n",
    "        true_most_frequent_classes = mode(trials_true, axis=1)[0].flatten()\n",
    "        print(true_most_frequent_classes)\n",
    "        accur = accuracy_score(true_most_frequent_classes, predicted_most_frequent_classes)\n",
    "        f1 = f1_score(true_most_frequent_classes, predicted_most_frequent_classes, average='weighted')\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(true_most_frequent_classes, predicted_most_frequent_classes)\n",
    "        acc.append (accur)\n",
    "        fscore.append (f1)\n",
    "        confusion.append (cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
